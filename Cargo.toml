[package]
name = "calf"
version = "0.1.0"
edition = "2024"
description = "Candle-based LLM Inference Framework"

[[bin]]
name = "calf"
path = "src/main.rs"

[dependencies]
anyhow = "1.0"
candle-core = { git = "https://github.com/apepkuss/candle.git", rev = "f5838914f788d3950d0a25042cffe199d9325a9e" }
candle-nn = { git = "https://github.com/apepkuss/candle.git", rev = "f5838914f788d3950d0a25042cffe199d9325a9e" }
candle-transformers = { git = "https://github.com/apepkuss/candle.git", rev = "f5838914f788d3950d0a25042cffe199d9325a9e" }
clap = { version = "4.0", features = ["derive"] }
hf-hub = "0.3"
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
serde_yaml = "0.9"
thiserror = "1.0"
tokenizers = "0.15"
tokio = { version = "1.0", features = ["full"] }
tracing = "0.1"
tracing-chrome = "0.7"
tracing-subscriber = "0.3"
uuid = { version = "1.0", features = ["v4", "serde"] }

[features]
default = []
accelerate = [
    "candle-core/accelerate",
    "candle-nn/accelerate",
    "candle-transformers/accelerate"
]
cuda = [
    "candle-core/cuda",
    "candle-nn/cuda",
    "candle-transformers/cuda"
]
mkl = [
    "candle-core/mkl",
    "candle-nn/mkl",
    "candle-transformers/mkl"
]
